---
entity_type: Task
entity_id: tsk-023-1768721377517
entity_name: AI API - Vault Ontology Schema 컨텍스트 자동 주입
created: '2026-01-18'
updated: '2026-01-18'
status: done
project_id: prj-023
parent_id: prj-023
assignee: 김은향
priority: medium
start_date: '2026-01-18'
due: '2026-01-18'
aliases:
- tsk-023-1768721377517
tags: []
type: dev
---

# AI API - Vault Ontology Schema 컨텍스트 자동 주입

## 설명

모든 AI API 호출 시 `00_Meta/Vault_Ontology_Schema.md` 내용을 system prompt에 자동 주입하여 LLM이 Vault 엔티티 관계와 스키마를 이해하고 컨텍스트 기반 추론을 수행할 수 있도록 함.

## 체크리스트

- [x] ontology_loader.py 신규 생성 (캐싱 + lazy load)
- [x] llm_service.py call_llm() 수정 (include_ontology 파라미터)
- [x] main.py startup에 pre-load 추가

## 변경 파일

| 파일 | 변경 |
|------|------|
| `api/utils/ontology_loader.py` | 신규 (79줄) - 캐시 로더 |
| `api/services/llm_service.py` | +11줄 - `include_ontology` 파라미터 |
| `api/main.py` | +6줄 - startup pre-load |

## 기술 결정

- **주입 위치**: `llm_service.py` (모든 AI 호출의 단일 진입점)
- **캐싱**: 모듈 레벨 싱글톤 (서버 수명 동안 1회만 로드)
- **기본값**: `include_ontology=True` (자동 적용, 필요시 opt-out)
- **토큰 오버헤드**: ~2,500 tokens/호출

## 커밋

- `e37ac370e` feat(ai): inject Vault Ontology Schema in all AI API calls

## 짧은 회고

워크트리 기반 개발로 main 브랜치 오염 없이 깔끔하게 구현 완료.
