---
entity_type: Task
entity_id: tsk-023-1768628306653
entity_name: Dashboard - Confidence Scorecard
created: '2026-01-17'
updated: '2026-01-17'
status: done
closed: '2026-01-17'
project_id: prj-023
parent_id: prj-023
assignee: 김은향
priority: medium
start_date: '2026-01-17'
due: '2026-01-17'
aliases:
- tsk-023-1768628306653
tags: []
type: dev
---

# Dashboard - Confidence Scorecard

## 설명

가설/프로젝트의 구체성에 따라 Confidence 점수를 자동 조정하는 Scorecard 시스템 구현.

**목적**:
- 수치 목표가 명확한 가설은 confidence 상향
- 모호한 정성적 서술만 있는 가설은 confidence 하향
- LOOP_PHILOSOPHY 8.1 준수: "숫자의 신뢰 구조가 없으면 그럴듯한 점수로 끝난다"

---

### 작업 로그

#### 2026-01-17 15:01
**개요**: Confidence Scorecard 시스템 구현 완료

**변경사항**:
- 개발: impact_model_config.yml에 confidence_scorecard 섹션 추가 (v1.4.0)
- 개발: api/utils/impact_calculator.py에 calculate_confidence_with_scorecard() 함수 구현
- 개발: api/prompts/expected_impact.py에 _build_confidence_guidelines() 함수 추가
- 수정: api/routers/impact_batch.py에서 scorecard 적용 (경고만이 아닌 실제 적용)

**파일 변경** (총 4개):
- `impact_model_config.yml`: confidence_scorecard 섹션 추가 (bonus/penalty 규칙, detection 로직)
- `api/utils/impact_calculator.py`: scorecard 계산 로직 및 helper 함수 (_check_quantified, _check_keywords, _parse_horizon_days)
- `api/prompts/expected_impact.py`: LLM에게 scorecard 가이드라인 제공하는 함수
- `api/routers/impact_batch.py`: scorecard 검증 및 적용, 타입 안전성 개선

**Codex 리뷰**: ✅ 통과 (이슈 2개 수정)
- Issue 1: LLM confidence 값의 타입 안전성 (string/None 처리 추가)
- Issue 2: Config 버전 헤더 불일치 (v1.2.0 → v1.4.0 수정)

**결과**: ✅ 빌드 성공, 배포 완료, API 정상 동작 확인

**커밋**: `38e7e4ace` on branch `task/tsk-023-1768628306653`

---

## Notes

### Tech Spec

**Architecture Compliance:**
- Parent Project: prj-023
- Target: loop (LOOP Dashboard v2)
- SSOT 원칙: Config → Calculator → Prompts (단방향 의존)

**File Structure:**
```
~/dev/loop/code/
├── impact_model_config.yml          # [MODIFY] confidence_scorecard 섹션 추가
├── api/
│   ├── utils/
│   │   └── impact_calculator.py     # [MODIFY] calculate_confidence_with_scorecard() 추가
│   ├── prompts/
│   │   └── expected_impact.py       # [MODIFY] _build_confidence_guidelines() 추가
│   └── routers/
│       └── impact_batch.py          # [MODIFY] scorecard 검증 통합
```

**Implementation Details:**

#### 1. impact_model_config.yml (v1.3.0 → v1.4.0)

```yaml
confidence_scorecard:
  enabled: true  # Feature flag
  base: 0.7
  cap:
    min: 0.3
    max: 0.95
  precision: 2  # 소수점 둘째자리까지

  # === Detection Rules (정규식 + 키워드) ===
  detection:
    quantified_pattern: "\\d+(\\.\\d+)?\\s*(%|건|원|점|명|회|일|주|개월)"
    measurement_keywords:
      - "Amplitude"
      - "Firebase"
      - "Mixpanel"
      - "RevenueCat"
      - "A/B"
      - "퍼널"
      - "이벤트"
      - "쿼리"
    controlled_keywords:
      - "A/B"
      - "RCT"
      - "split"
      - "코호트"
      - "대조군"
      - "실험군"
    external_keywords:
      - "파트너"
      - "규제"
      - "승인"
      - "외부"
      - "제3자"
    horizon_thresholds:
      short_days: 90   # <= 90일 = short
      long_days: 180   # > 180일 = long

  bonus:
    - id: "success_criteria_quantified"
      adjustment: 0.1
      field: "success_criteria"
      detection_type: "regex"  # quantified_pattern 사용
    - id: "measurement_method_specific"
      adjustment: 0.05
      field: "measurement"
      detection_type: "keywords"  # measurement_keywords 사용
    - id: "counterfactual_controlled"
      adjustment: 0.1
      field: "counterfactual"
      detection_type: "keywords"  # controlled_keywords 또는 값="controlled"
    - id: "horizon_short"
      adjustment: 0.05
      field: "horizon"
      detection_type: "threshold"  # <= short_days

  penalty:
    - id: "success_criteria_vague"
      adjustment: -0.1
      field: "success_criteria"
      detection_type: "no_match"  # quantified_pattern 매칭 실패
      exclusive_with: "success_criteria_quantified"  # 상호 배타
    - id: "no_measurement"
      adjustment: -0.1
      field: "measurement"
      detection_type: "empty_or_tbd"  # null, "", "TBD", "미정"
    - id: "horizon_long"
      adjustment: -0.1
      field: "horizon"
      detection_type: "threshold"  # > long_days
      exclusive_with: "horizon_short"  # 상호 배타
    - id: "no_counterfactual"
      adjustment: -0.05
      field: "counterfactual"
      detection_type: "value_match"  # 값="none" 또는 null
    - id: "external_dependency"
      adjustment: -0.1
      field: "assumptions"  # assumptions 배열에서 검색
      detection_type: "keywords"  # external_keywords 사용
```

#### 2. impact_calculator.py - Scoring Algorithm

```python
def calculate_confidence_with_scorecard(
    hypothesis: Dict[str, Any],
    scorecard: Dict[str, Any]
) -> Dict[str, Any]:
    """
    가설의 구체성에 따라 Confidence를 계산.

    Algorithm:
    1. base (0.7)에서 시작
    2. bonus 조건 순회: 매칭 시 adjustment 누적
    3. penalty 조건 순회: 매칭 시 adjustment 누적 (exclusive_with 체크)
    4. total = base + sum(adjustments)
    5. clip(total, min, max)
    6. round(total, precision)

    Conflict Resolution:
    - exclusive_with 필드가 있으면 해당 조건이 이미 적용된 경우 skip
    - quantified ↔ vague, short ↔ long 상호 배타

    Missing Field Handling:
    - 필드 없음(None): 해당 bonus 미적용, penalty는 조건에 따라 적용
    - 빈 문자열(""): empty_or_tbd로 처리

    Returns:
        {
            "confidence": 0.75,
            "base": 0.7,
            "adjustments": [
                {"id": "success_criteria_quantified", "adjustment": 0.1, "applied": True, "reason": "30% 매칭"}
            ],
            "total_adjustment": 0.05,
            "capped": False,
            "capped_from": null  # cap 적용 전 값 (capped=True일 때만)
        }
    """
```

**Detection Helper Functions:**

```python
def _check_quantified(text: str, pattern: str) -> Tuple[bool, str]:
    """정규식으로 수치 목표 포함 여부 확인. (matched, match_text) 반환"""

def _check_keywords(text: str, keywords: List[str]) -> Tuple[bool, str]:
    """키워드 매칭. (matched, matched_keyword) 반환"""

def _parse_horizon_days(horizon: str) -> Optional[int]:
    """horizon 문자열을 일수로 변환. '2months' → 60, '1year' → 365"""
```

#### 3. expected_impact.py - Prompt Guidelines

```python
def _build_confidence_guidelines(scorecard: Dict) -> str:
    """
    Config의 scorecard를 LLM 프롬프트용 마크다운 텍스트로 변환.

    Output Format:
    '''
    ### Confidence Scorecard 가이드라인

    **기본 Confidence**: 0.7 (범위: 0.3 ~ 0.95)

    **보너스 조건 (+):**
    - success_criteria에 수치 포함 (%, 건, 원 등): +0.1
    - measurement에 구체적 도구 명시: +0.05
    - A/B 테스트 등 통제 실험: +0.1
    - 3개월 이내 검증 가능: +0.05

    **페널티 조건 (-):**
    - success_criteria가 정성적 서술만: -0.1
    - measurement 없음: -0.1
    - 6개월 초과 장기 검증: -0.1
    - 대조군 없는 단순 관측: -0.05
    - 외부 의존도 높음: -0.1

    **주의**: 보너스와 페널티는 상호 배타적 (quantified ↔ vague)
    '''
    """
```

**Integration Point**: `build_expected_impact_prompt()` 마지막에 추가

```python
def build_expected_impact_prompt(...) -> str:
    context = build_strategic_context(...)
    command = _build_expected_impact_command()

    # Scorecard 가이드라인 추가 (v1.4.0)
    config = load_impact_config()
    scorecard = config.get("confidence_scorecard", {})
    if scorecard.get("enabled", False):
        guidelines = _build_confidence_guidelines(scorecard)
        return f"{context}\n{command}\n{guidelines}"

    return f"{context}\n{command}"
```

#### 4. impact_batch.py - Validation Integration

**호출 위치**: `suggest_batch()` 엔드포인트, LLM 응답 파싱 후

```python
# Line ~975 (confidence 추출 후)
confidence_value = conf_data.get("value", 0.7)

# Scorecard 검증 (v1.4.0)
config = load_impact_config()
scorecard = config.get("confidence_scorecard", {})
if scorecard.get("enabled", False):
    scorecard_result = calculate_confidence_with_scorecard(
        hypothesis=content,  # LLM 응답에서 hypothesis 관련 필드
        scorecard=scorecard
    )

    # 차이가 0.15 이상이면 경고
    llm_confidence = confidence_value
    calc_confidence = scorecard_result["confidence"]
    if abs(llm_confidence - calc_confidence) >= 0.15:
        warnings.append({
            "code": "CONFIDENCE_MISMATCH",
            "llm_value": llm_confidence,
            "scorecard_value": calc_confidence,
            "adjustments": scorecard_result["adjustments"]
        })

    # (선택) LLM 값 대신 scorecard 값 사용
    # confidence_value = calc_confidence
```

**Validation Error Schema:**

```python
class ScorecardValidationWarning(TypedDict):
    code: Literal["CONFIDENCE_MISMATCH"]
    llm_value: float
    scorecard_value: float
    adjustments: List[Dict[str, Any]]
```

**Edge Cases (상세화):**

| 상황 | 처리 |
|------|------|
| hypothesis 필드 전체 없음 | base(0.7) 반환, adjustments=[] |
| success_criteria="" | vague 페널티 적용 |
| success_criteria=None | vague 페널티 적용 |
| horizon 파싱 실패 | short/long 모두 미적용 |
| quantified+vague 동시 매칭 | exclusive_with로 방지 (quantified 우선) |
| cap 적용됨 | capped=True, capped_from에 원래 값 기록 |

---

### Todo
- [ ] `impact_model_config.yml`에 confidence_scorecard 섹션 추가 (v1.4.0)
- [ ] `api/utils/impact_calculator.py`에 `calculate_confidence_with_scorecard()` 함수 구현
- [ ] `api/prompts/expected_impact.py`에 `_build_confidence_guidelines()` 함수 추가
- [ ] `build_expected_impact_prompt()` 수정하여 scorecard 가이드라인 포함
- [ ] `api/routers/impact_batch.py`에서 LLM 응답 confidence 검증 로직 추가
- [ ] 기존 테스트 통과 확인 (`npm run build`)
- [ ] Unit test 작성 (scorecard 계산 로직)

---

## 참고

- `docs/mcp_logic_supplement.md` - Confidence Scorecard 원본 제안
- `impact_model_config.yml` - Impact 모델 SSOT
- prj-023 아키텍처 규칙: SSOT + Clean Architecture
