---
entity_type: Task
entity_id: tsk-000gpt-1768282752487
entity_name: Impact Batch API v2 - Response Schema Enhancement
created: '2026-01-13'
updated: '2026-01-13'
status: done
project_id: prj-vault-gpt
parent_id: prj-vault-gpt
assignee: 김은향
priority: medium
start_date: '2026-01-13'
due: '2026-01-13'
completed: '2026-01-13'
aliases:
- tsk-000gpt-1768282752487
tags: []
type: dev
notes: "# Impact Batch API v2 - Response Schema Enhancement\n\n## 설명\n\nEnhance Impact\
  \ Batch API response schemas to provide complete scoring context, structured reasoning,\
  \ and apply-ready patches for LLM (ChatGPT MCP) suggestions.\n\n## Notes\n\n###\
  \ Tech Spec\n\n**Codex Review Findings Applied (2026-01-13):**\n\nThis PRD has been\
  \ enhanced based on 5 critical findings from Codex code review:\n\n1. **Finding\
  \ #1: Cross-Module Impact** (projects.py, autofill.py, ai.py)\n\n   - `calculate_expected_score()`\
  \ return type change affects 4 modules, not just impact_batch.py\n   - **Solution**:\
  \ Create new `_with_breakdown()` function + legacy wrapper for backward compatibility\n\
  \   - **Location**: Phase 0 + Phase 1\n\n2. **Finding #2: Schema Mismatch** (v5.3\
  \ compliance)\n\n   - Current code puts `contributes` inside `expected_impact`,\
  \ but v5.3 schema uses top-level fields\n   - Correct structure: `condition_contributes`\
  \ and `track_contributes` at entity root, not nested\n   - **Solution**: Fix all\
  \ field references in suggest_batch endpoint\n   - **Location**: Phase 4 Critical\
  \ Fix #1\n\n3. **Finding #3: LLM Prompt Missing Fields**\n\n   - Prompt in `prompts/expected_impact.py`\
  \ only requests 4 fields (tier, magnitude, confidence, summary)\n   - v5.3 schema\
  \ needs 7 additional fields: validates, primary_hypothesis_id, condition_contributes,\
  \ track_contributes, assumptions, evidence_refs, linking_reason\n   - **Solution**:\
  \ Extend prompt template with complete v5.3 output schema\n   - **Location**: Phase\
  \ 2 (File 2)\n\n4. **Finding #4: Missing Config Keys**\n\n   - Response models reference\
  \ `hypothesis_rules` and `display_rules` that don't exist in impact_model_config.yml\n\
  \   - **Solution**: Extend config file with 2 new sections (hypothesis_rules, display_rules)\n\
  \   - **Location**: Phase 2 (File 1)\n\n5. **Finding #5: Incomplete Request/Response\
  \ Schemas**\n\n   - Preview/Apply endpoints missing complete validation error structure\n\
  \   - No field-level validation error format in ApplyBatchResponse\n   - PreviewRequest\
  \ missing fields needed for validation checks\n   - **Solution**: Add 3 new Pydantic\
  \ models (FieldValidationError, PreviewRequest, PreviewResponse) with complete schemas\n\
  \   - **Location**: Phase 3, Phase 5, Phase 6\n\n**Impact**: Scope increased from\
  \ 7 models → 10 models, 5.5 hours → 8.5 hours\n\n---\n\n**Architecture Compliance:**\n\
  \n- Parent Project: prj-vault-gpt\n- Architecture Pattern: FastAPI + REST + MCP\
  \ (Model Context Protocol)\n- Deployment: Docker on NAS (port 8082 → 8081)\n- Client:\
  \ ChatGPT Developer Mode via MCP\n\n**Critical Bug to Fix**:Line 381-386, 452-457\
  \ in `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`:\n\n- Passing\
  \ invalid `contributes` parameter to `calculate_expected_score()`\n- Function returns\
  \ `float`, code expects `dict` with `[\"score\"]` key\n- This is a **BLOCKER** -\
  \ must fix first\n\n**File Structure:**\n\n```\n/Users/gim-eunhyang/dev/loop/public/api/\n\
  ├── models/impact_batch.py              [MODIFY] Add 7 new Pydantic models\n├──\
  \ routers/impact_batch.py             [MODIFY] Fix bug + enhance 4 endpoints\n├──\
  \ utils/impact_calculator.py          [MODIFY] Change return type to dict\n└── prompts/expected_impact.py\
  \          [READ] Verify LLM fields\n\n/Users/gim-eunhyang/dev/loop/public/\n├──\
  \ impact_model_config.yml             [READ] Scoring rules SSOT\n└── 00_Meta/schema_constants.yaml\
  \       [READ] Validation rules\n```\n\n**Implementation Details:**\n\n**Phase 0:\
  \ Cross-Module Impact Analysis (Codex Finding #1)**\n\n- **CRITICAL**: `calculate_expected_score()`\
  \ return type change affects 4 modules:\n  1. `impact_batch.py` (lines 381-386,\
  \ 452-457) - Already identified in original bug\n  2. `projects.py` (lines 190-194)\
  \ - Project-level scoring\n  3. `autofill.py` (lines 268-307) - Autofill impact\
  \ suggestions\n  4. `ai.py` (lines 837-883) - AI-driven impact analysis\n- **Strategy**:\
  \ Create new helper function to maintain backward compatibility:\n\n  ```python\n\
  \  # In impact_calculator.py\n  def calculate_expected_score_with_breakdown(tier,\
  \ magnitude, confidence) -> Dict[str, Any]:\n      \"\"\"New function with full\
  \ breakdown (Phase 1 implementation)\"\"\"\n      return {\n          \"score\"\
  : float,\n          \"tier_points\": float,\n          \"confidence\": float,\n\
  \          \"tier\": str,\n          \"magnitude\": str,\n          \"formula\"\
  : str,\n          \"max_score_by_tier\": float,\n          \"normalized_10\": float,\n\
  \      }\n  \n  def calculate_expected_score(tier, magnitude, confidence) -> float:\n\
  \      \"\"\"Legacy function - delegates to new function for compatibility\"\"\"\
  \n      return calculate_expected_score_with_breakdown(tier, magnitude, confidence)[\"\
  score\"]\n  ```\n- **Migration Plan**:\n  1. Add new `_with_breakdown()` function\n\
  \  2. Keep old function as compatibility wrapper\n  3. Update only `impact_batch.py`\
  \ to use new function\n  4. Other modules (projects.py, autofill.py, ai.py) continue\
  \ using legacy function\n  5. Mark legacy function for deprecation in v3\n\n**Phase\
  \ 1: Fix Critical Bug (BLOCKER)**\n\n- File: `/Users/gim-eunhyang/dev/loop/public/api/utils/impact_calculator.py`\n\
  - Function: Add `calculate_expected_score_with_breakdown()` (new function)\n- Update\
  \ `calculate_expected_score()` to delegate to new function\n- Lines to modify: 34-69\
  \ (expand to \\~80 lines for new function + wrapper)\n- Impact: Only `impact_batch.py`\
  \ calls new function with breakdown, other callers unaffected\n\n**Phase 2: Extend\
  \ Config Files (Codex Finding #4 - Missing Config Keys)**\n\n**File 1:** `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`\n\
  \n- Add new sections for `hypothesis_rules` and `display_rules`:\n\n  ```yaml\n\
  \  # Existing sections (magnitude_points, confidence_multipliers, tier_ordering)\n\
  \  # ...\n  \n  # NEW: Hypothesis linking rules (Codex Finding #4)\n  hypothesis_rules:\n\
  \    strategic_must_validate: true  # Strategic tier must have validates list\n\
  \    max_hypotheses_per_project: 3  # Limit hypothesis links\n    weight_sum_max:\
  \ 1.0            # Max total weight for contributes\n  \n  # NEW: Display formatting\
  \ rules (Codex Finding #4)\n  display_rules:\n    score_display_mode: \"stars_5\"\
  \   # \"stars_5\" | \"normalized_10\" | \"raw\"\n    decimal_places: 2         \
  \      # Rounding precision\n    show_breakdown: true            # Include calculation\
  \ breakdown in responses\n    star_thresholds:                # Score → star mapping\n\
  \      5: [9.0, 10.0]\n      4: [7.0, 9.0]\n      3: [5.0, 7.0]\n      2: [3.0,\
  \ 5.0]\n      1: [0.0, 3.0]\n  ```\n\n**File 2:** `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py`\n\
  \n- Update LLM prompt template (lines 219-290) to include v5.3 schema fields:\n\n\
  \  ```python\n  # Expand existing prompt with new output schema\n  EXPECTED_IMPACT_PROMPT\
  \ = \"\"\"\n  ... (existing context) ...\n  \n  Required Output JSON Schema (v5.3\
  \ - Updated):\n  {{\n    // EXISTING FIELDS\n    \"tier\": \"strategic|operational|tactical\"\
  ,\n    \"impact_magnitude\": \"transformative|high|moderate|low|minimal\",\n   \
  \ \"confidence\": 0.0-1.0,\n    \"summary\": \"Brief impact summary\",\n  \n   \
  \ // NEW: Hypothesis linking (Codex Finding #3)\n    \"validates\": [\"hyp-001\"\
  , \"hyp-002\"],      // Hypothesis IDs this validates\n    \"primary_hypothesis_id\"\
  : \"hyp-001\",        // Primary hypothesis (optional)\n  \n    // NEW: Strategic\
  \ contribution (Codex Finding #2)\n    \"condition_contributes\": [\n      {{\"\
  condition_id\": \"cnd-3y-001\", \"weight\": 0.5}},\n      {{\"condition_id\": \"\
  cnd-3y-002\", \"weight\": 0.3}}\n    ],\n    \"track_contributes\": [\n      {{\"\
  track_id\": \"trk-001\", \"weight\": 0.4}}\n    ],\n  \n    // NEW: Reasoning &\
  \ evidence (Codex Finding #3)\n    \"assumptions\": [\"Key assumption 1\", \"Key\
  \ assumption 2\"],\n    \"evidence_refs\": [\"Link to data\", \"Previous project\
  \ results\"],\n    \"linking_reason\": \"Why this links to selected hypotheses/conditions/tracks\"\
  ,\n  \n    // EXISTING: Reasoning fields\n    \"tier_reason\": \"Why this tier\"\
  ,\n    \"magnitude_reason\": \"Why this magnitude\",\n    \"confidence_reason\"\
  : \"Confidence factors\"\n  }}\n  \n  IMPORTANT RULES (v5.3 Schema):\n  - `expected_impact`\
  \ object only contains: statement, metric, target (NO contributes inside)\n  - `condition_contributes`\
  \ and `track_contributes` are TOP-LEVEL fields\n  - Strategic tier SHOULD have at\
  \ least 1 item in `validates` list\n  - Total weight in contributes lists should\
  \ not exceed 1.0\n  \"\"\"\n  ```\n\n**Phase 3: Add New Pydantic Models**\n\n- File:\
  \ `/Users/gim-eunhyang/dev/loop/public/api/models/impact_batch.py`\n- Add 10 new\
  \ models (3 more than originally planned - Codex Finding #5):\n   1. `OutputContract`\
  \ - Required fields specification\n   2. `ScoringContext` - Impact model context\
  \ for LLM\n   3. `ApplyPatch` - SSOT-ready patch format (v5.3 schema compliant)\n\
  \   4. `StructuredReasoning` - Audit-ready reasoning breakdown\n   5. `CalculatedFields`\
  \ - Complete score calculation results\n   6. `FieldValidationError` - Field-level\
  \ error structure (NEW - Codex Finding #5)\n   7. `PreviewRequest` - Complete preview\
  \ request schema (NEW - Codex Finding #5)\n   8. `PreviewResponse` - Complete preview\
  \ response schema (NEW - Codex Finding #5)\n   9. Enhanced `WorklistResponse` -\
  \ Add contract + context\n  10. Enhanced `SuggestBatchResponse` - Add schema_version\
  \ + impact_model_version\n\n**Phase 3a: Enhance Worklist Endpoint**\n\n- File: `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`\n\
  - Endpoint: `POST /api/mcp/impact/expected/worklist` (\\~line 210)\n- Add to response:\n\
  \  - `required_output_contract`: must_set fields, contributes_rules, hypothesis_rules\n\
  \  - `scoring_context`: impact_model_version, tier_points table, display_rules\n\
  - Load from: `impact_model_config.yml` + `00_Meta/schema_constants.yaml`\n\n**Phase\
  \ 4: Fix Suggest Batch Endpoint (Codex Findings #2, #3, #4)**\n\n**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`**Endpoint:**\
  \ `POST /api/mcp/impact/expected/suggest-batch` (\\~line 280-420)\n\n**Critical\
  \ Fix #1: Schema Mismatch (Codex Finding #2)**\n\n- **Problem**: Current code uses\
  \ `contributes` as top-level field, but v5.3 schema uses:\n  - `condition_contributes:\
  \ List[{condition_id, weight}]` - top-level\n  - `track_contributes: List[{track_id,\
  \ weight}]` - top-level\n  - `expected_impact: {statement, metric, target}` - nested,\
  \ no contributes\n- **Fix**: Update all field references:\n\n  ```python\n  # OLD\
  \ (incorrect)\n  apply_patch = {\n      \"expected_impact\": {\n          \"statement\"\
  : llm_response[\"statement\"],\n          \"contributes\": llm_response.get(\"contributes\"\
  , [])  # WRONG LOCATION\n      }\n  }\n  \n  # NEW (correct per v5.3 schema)\n \
  \ apply_patch = {\n      \"expected_impact\": {\n          \"statement\": llm_response[\"\
  statement\"],\n          \"metric\": llm_response.get(\"metric\"),\n          \"\
  target\": llm_response.get(\"target\")\n      },\n      \"condition_contributes\"\
  : llm_response.get(\"condition_contributes\", []),\n      \"track_contributes\"\
  : llm_response.get(\"track_contributes\", [])\n  }\n  ```\n\n**Critical Fix #2:\
  \ LLM Prompt Missing New Fields (Codex Finding #3)**\n\n- **Problem**: Current prompt\
  \ in `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py` (lines\
  \ 219-266) only requests:\n  - tier, impact_magnitude, confidence, summary\n- **Missing\
  \ fields needed by v5.3 schema**:\n  - `validates: List[str]` - Hypothesis IDs this\
  \ project validates\n  - `primary_hypothesis_id: str` - Primary hypothesis being\
  \ tested\n  - `condition_contributes: List[{condition_id, weight}]` - Condition\
  \ contributions\n  - `track_contributes: List[{track_id, weight}]` - Track contributions\n\
  \  - `assumptions: List[str]` - Key assumptions\n  - `evidence_refs: List[str]`\
  \ - Supporting evidence references\n  - `linking_reason: str` - Why this project\
  \ links to hypotheses/conditions/tracks\n- **Fix Required**: Update prompt template\
  \ to include new output schema:\n\n  ```python\n  # Add to prompts/expected_impact.py\
  \ lines 260-280\n  \"\"\"\n  Required Output JSON Schema (v5.3):\n  {{\n    \"tier\"\
  : \"strategic|operational|tactical\",\n    \"impact_magnitude\": \"transformative|high|moderate|low|minimal\"\
  ,\n    \"confidence\": 0.0-1.0,\n    \"summary\": \"...\",\n  \n    // NEW FIELDS\
  \ (v5.3)\n    \"validates\": [\"hyp-001\", \"hyp-002\"],           // Hypothesis\
  \ IDs being tested\n    \"primary_hypothesis_id\": \"hyp-001\",            // Primary\
  \ hypothesis\n    \"condition_contributes\": [\n      {{\"condition_id\": \"cnd-3y-001\"\
  , \"weight\": 0.5}},\n      {{\"condition_id\": \"cnd-3y-002\", \"weight\": 0.3}}\n\
  \    ],\n    \"track_contributes\": [\n      {{\"track_id\": \"trk-001\", \"weight\"\
  : 0.4}}\n    ],\n    \"assumptions\": [\"List key assumptions here\"],\n    \"evidence_refs\"\
  : [\"Link to evidence/data sources\"],\n    \"linking_reason\": \"Explain why this\
  \ project contributes to these hypotheses/conditions/tracks\",\n  \n    // REASONING\
  \ FIELDS\n    \"tier_reason\": \"Why this tier was chosen\",\n    \"magnitude_reason\"\
  : \"Why this magnitude\",\n    \"confidence_reason\": \"Factors affecting confidence\"\
  \n  }}\n  \"\"\"\n  ```\n\n**Critical Fix #3: Missing Config Keys (Codex Finding\
  \ #4)**\n\n- **Problem**: Response models reference keys not in `impact_model_config.yml`:\n\
  \  - `hypothesis_rules` - not defined\n  - `display_rules` - not defined anywhere\n\
  - **Fix Options**:\n  1. **Option A (Recommended)**: Extend `impact_model_config.yml`\
  \ with new sections:\n\n     ```yaml\n     # Add to impact_model_config.yml\n  \
  \   hypothesis_rules:\n       strategic_must_validate: true\n       max_hypotheses_per_project:\
  \ 3\n       weight_sum_max: 1.0\n     \n     display_rules:\n       score_display_mode:\
  \ \"stars_5\"  # or \"normalized_10\"\n       decimal_places: 2\n       show_breakdown:\
  \ true\n     ```\n  2. **Option B**: Hard-code defaults in Python and document in\
  \ schema_constants.yaml\n  3. **Option C**: Remove from response schema (breaks\
  \ client contract)\n- **Decision**: Use Option A - extend config file\n- **Files\
  \ to modify**:\n  - `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`\
  \ (add 2 new sections)\n  - `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`\
  \ (load new sections)\n\n**Critical Fix #4: Bug in Score Calculation Call**\n\n\
  - Remove `contributes` parameter from `calculate_expected_score_with_breakdown()`\
  \ call (line 381-386, 452-457)\n- Use `score_result[\"score\"]` instead of treating\
  \ result as float\n- Extract all LLM fields including new v5.3 fields listed above\n\
  \n**Implementation Steps:**\n\n1. Update LLM prompt template in `prompts/expected_impact.py`\
  \ (lines 260-290)\n2. Extend `impact_model_config.yml` with `hypothesis_rules` +\
  \ `display_rules`\n3. Fix score calculation call (remove contributes param)\n4.\
  \ Build `StructuredReasoning` from LLM response (tier_reason, magnitude_reason,\
  \ assumptions, evidence_refs, linking_reason)\n5. Build `CalculatedFields` from\
  \ score_result dict\n6. Build `ApplyPatch` with correct v5.3 schema structure (expected_impact,\
  \ condition_contributes, track_contributes at correct levels)\n7. Add `schema_version:\
  \ \"v2\"` and `impact_model_version` to response\n8. Keep `suggested_fields` for\
  \ backward compatibility (mark deprecated)\n\n**Phase 5: Enhance Preview Endpoint\
  \ (Codex Finding #5 - Complete Request/Response)**\n\n**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`**Endpoint:**\
  \ `POST /api/mcp/impact/expected/preview` (\\~line 422-500)\n\n**Complete Request\
  \ Schema (Codex Finding #5):**\n\n```python\nclass PreviewRequest(BaseModel):\n\
  \    \"\"\"Complete request schema for preview validation\"\"\"\n    project_id:\
  \ str\n    apply_patch: ApplyPatch  # From Phase 2 models\n\n    # NEW: Fields needed\
  \ for validation checks\n    parent_chain: Optional[List[str]] = None  # For hierarchy\
  \ validation\n    existing_contributes: Optional[Dict] = None  # Current state for\
  \ diff\n    validate_weights: bool = True  # Enable weight sum check\n    validate_hypothesis_links:\
  \ bool = True  # Enable strategic tier check\n```\n\n**Enhanced Validation Warnings:**\n\
  \n1. **Weight Sum Validation**:\n\n   - Check `condition_contributes` weight sum\
  \ &lt;= 1.0\n   - Check `track_contributes` weight sum &lt;= 1.0\n   - Warning format:\
  \ `{\"field\": \"condition_contributes\", \"issue\": \"weight_sum_exceeded\", \"\
  current\": 1.2, \"max\": 1.0}`\n\n2. **Strategic Tier Hypothesis Validation**:\n\
  \n   - If tier == \"strategic\", must have `validates` list with at least 1 hypothesis\n\
  \   - Warning format: `{\"field\": \"validates\", \"issue\": \"strategic_requires_hypothesis\"\
  , \"tier\": \"strategic\"}`\n\n3. **Parent Chain Alignment** (NEW):\n\n   - Check\
  \ if `condition_contributes` conditions are in parent project's conditions\n   -\
  \ Check if `track_contributes` tracks align with parent project's tracks\n   - Warning\
  \ format: `{\"field\": \"condition_contributes\", \"issue\": \"condition_not_in_parent_chain\"\
  , \"condition_id\": \"cnd-3y-001\"}`\n\n4. **Hypothesis Existence Check** (NEW):\n\
  \n   - Verify all `validates` hypothesis IDs exist in vault\n   - Warning format:\
  \ `{\"field\": \"validates\", \"issue\": \"hypothesis_not_found\", \"hypothesis_id\"\
  : \"hyp-999\"}`\n\n**Complete Response Schema (Codex Finding #5):**\n\n```python\n\
  class PreviewResponse(BaseModel):\n    \"\"\"Complete response with validation results\"\
  \"\"\n    project_id: str\n    status: str  # \"valid\" | \"warnings\" | \"errors\"\
  \n\n    # Validation results\n    validation_passed: bool\n    warnings: List[Dict[str,\
  \ Any]]  # Structured warnings (non-blocking)\n    errors: List[Dict[str, Any]]\
  \    # Structured errors (blocking)\n\n    # Preview of changes\n    apply_patch_preview:\
  \ ApplyPatch\n    impact_preview: CalculatedFields  # Show expected score\n\n  \
  \  # Diff from current state\n    changes_summary: Dict[str, Any]  # {\"added\"\
  : [...], \"removed\": [...], \"modified\": [...]}\n```\n\n**Phase 6: Enhance Apply\
  \ Batch Validation (Codex Finding #5 - Field-Level Errors)**\n\n**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`**Endpoint:**\
  \ `POST /api/mcp/impact/expected/apply-batch`\n\n**Complete Request Schema:**\n\n\
  ```python\nclass ApplyBatchRequest(BaseModel):\n    \"\"\"Batch apply with per-project\
  \ patches\"\"\"\n    run_id: str\n    applies: List[Dict[str, Any]]  # [{project_id,\
  \ apply_patch}, ...]\n    dry_run: bool = False  # Preview mode without writing\n\
  ```\n\n**Enhanced Response Schema (Codex Finding #5):**\n\n```python\nclass ApplyBatchResponse(BaseModel):\n\
  \    \"\"\"Complete response with field-level validation\"\"\"\n    run_id: str\n\
  \    total_requested: int\n    succeeded: int\n    failed: int\n    dry_run: bool\n\
  \n    # Per-project results\n    results: List[ApplyResult]\n\n    # Summary\n \
  \   summary: Dict[str, Any]\n\nclass ApplyResult(BaseModel):\n    \"\"\"Per-project\
  \ apply result with field-level errors\"\"\"\n    project_id: str\n    status: str\
  \  # \"success\" | \"validation_error\" | \"write_error\" | \"skipped\"\n\n    #\
  \ Success details\n    applied_patch: Optional[ApplyPatch] = None\n    file_path:\
  \ Optional[str] = None\n\n    # Field-level validation errors (NEW - Codex Finding\
  \ #5)\n    validation_errors: List[FieldValidationError] = []\n\n    # General error\n\
  \    error: Optional[str] = None\n\nclass FieldValidationError(BaseModel):\n   \
  \ \"\"\"Structured field-level error (NEW)\"\"\"\n    field_path: str  # e.g., \"\
  expected_impact.statement\", \"condition_contributes[0].weight\"\n    error_type:\
  \ str  # \"missing_required\" | \"invalid_type\" | \"invalid_value\" | \"constraint_violation\"\
  \n    message: str\n    expected: Optional[Any] = None  # Expected value/type\n\
  \    actual: Optional[Any] = None    # Actual value received\n    constraint: Optional[str]\
  \ = None  # Constraint rule violated\n```\n\n**Field-Level Validation Rules:**\n\
  \n1. **Required Fields**:\n\n   - `expected_impact.statement` - must be non-empty\
  \ string\n   - Error: `{\"field_path\": \"expected_impact.statement\", \"error_type\"\
  : \"missing_required\", \"message\": \"Impact statement is required\"}`\n\n2. **Type\
  \ Validation**:\n\n   - `condition_contributes[*].weight` - must be float 0.0-1.0\n\
  \   - Error: `{\"field_path\": \"condition_contributes[0].weight\", \"error_type\"\
  : \"invalid_type\", \"expected\": \"float\", \"actual\": \"string\"}`\n\n3. **Constraint\
  \ Validation**:\n\n   - Weight sum &lt;= 1.0\n   - Error: `{\"field_path\": \"condition_contributes\"\
  , \"error_type\": \"constraint_violation\", \"constraint\": \"weight_sum_max_1.0\"\
  , \"actual\": 1.3}`\n\n4. **Reference Validation**:\n\n   - Hypothesis IDs must\
  \ exist\n   - Error: `{\"field_path\": \"validates[0]\", \"error_type\": \"invalid_value\"\
  , \"message\": \"Hypothesis hyp-999 not found in vault\"}`\n\n**Implementation:**\n\
  \n- Parse each field in `apply_patch`\n- Collect all errors before returning (don't\
  \ fail fast)\n- Group errors by project_id\n- Return structured errors for LLM to\
  \ auto-fix\n\n**API Endpoints Modified:**\n\n- `POST /api/mcp/impact/expected/worklist`\
  \ - Add contract + context\n- `POST /api/mcp/impact/expected/suggest-batch` - Fix\
  \ bug + add apply_patch\n- `POST /api/mcp/impact/expected/preview` - Enhanced warnings\n\
  - `POST /api/mcp/impact/expected/apply-batch` - Field-level validation\n\n**Data\
  \ Models:**\n\n```python\n# New models\nOutputContract(must_set: List[str], contributes_rules:\
  \ Dict, hypothesis_rules: Dict)\nScoringContext(impact_model_version: str, tier_points:\
  \ Dict, display_rules: Dict)\nApplyPatch(expected_impact: Dict, hypothesis_links:\
  \ Dict, contributes: Dict)\nStructuredReasoning(tier_reason: str, magnitude_reason:\
  \ str, confidence_reason: str, assumptions: List, evidence_refs: List, linking_reason:\
  \ Dict, rollup_reason: Dict)\nCalculatedFields(magnitude_points: float, expected_score_raw:\
  \ float, max_score_by_tier: float, normalized_score_10: float, display_star_5: float,\
  \ calculation: str)\n\n# Enhanced responses\nWorklistResponse(run_id, total_matched,\
  \ items, required_output_contract, scoring_context)\nSuggestBatchResponse(run_id,\
  \ mode, schema_version, impact_model_version, suggestions, summary)\nSuggestBatchSuggestion(project_id,\
  \ status, apply_patch, suggested_fields, calculated_fields, reasoning, warnings,\
  \ error)\n```\n\n**Dependencies:**\n\n- No new packages required\n- Uses existing:\
  \ FastAPI, Pydantic, PyYAML\n\n**Key Functions:**\n\n```python\n# Modified function\
  \ signature\ndef calculate_expected_score(\n    tier: str,\n    magnitude: str,\n\
  \    confidence: float\n) -> Dict[str, Any]:\n    # Returns dict with score breakdown\
  \ instead of float\n\n# New helper (if needed)\ndef build_structured_reasoning(\n\
  \    llm_response: Dict[str, Any]\n) -> StructuredReasoning:\n    # Parse LLM response\
  \ into structured format\n```\n\n**Edge Cases:**\n\n1. **LLM returns incomplete\
  \ fields**: Use empty lists/None for optional fields (validates, contributes)\n\
  2. **Score calculation with invalid tier/magnitude**: Function should raise ValueError,\
  \ catch in endpoint and return error status\n3. **Weight sum &gt; 1.0**: Add warning\
  \ in preview, but don't block apply (human can override)\n4. **Missing impact_model_config.yml**:\
  \ Endpoint should return 500 with clear error message\n5. **Backward compatibility**:\
  \ Keep `suggested_fields` in response for old clients, but mark as deprecated in\
  \ docs\n\n### Todo\n\n**Phase 0: Cross-Module Impact Analysis (Codex Finding #1)**\n\
  \n- [ ] Identify all callers of `calculate_expected_score()` across 4 modules: impact_batch.py,\
  \ projects.py, autofill.py, ai.py\n\n- [ ] Document migration strategy: new function\
  \ with breakdown + legacy wrapper for compatibility\n\n**Phase 1: Fix Critical Bug\
  \ (BLOCKER)**\n\n- [ ] Add `calculate_expected_score_with_breakdown()` in `/Users/gim-eunhyang/dev/loop/public/api/utils/impact_calculator.py`\n\
  \n- [ ] Update `calculate_expected_score()` to delegate to new function (maintain\
  \ backward compatibility)\n\n- [ ] Update only `impact_batch.py` to call new `_with_breakdown()`\
  \ function (lines 381-386, 452-457)\n\n- [ ] Other modules (projects.py, autofill.py,\
  \ ai.py) continue using legacy wrapper\n\n**Phase 2: Extend Config Files (Codex\
  \ Finding #4)**\n\n- [ ] Add `hypothesis_rules` section to `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`\n\
  \n- [ ] Add `display_rules` section to `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`\n\
  \n- [ ] Update LLM prompt in `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py`\
  \ (lines 219-290) with v5.3 schema\n\n- [ ] Add new output fields: validates, primary_hypothesis_id,\
  \ condition_contributes, track_contributes, assumptions, evidence_refs, linking_reason\n\
  \n**Phase 3: Add New Pydantic Models (Codex Finding #5)**\n\n- [ ] Add 10 new Pydantic\
  \ models to `/Users/gim-eunhyang/dev/loop/public/api/models/impact_batch.py`\n\n\
  - [ ] OutputContract, ScoringContext, ApplyPatch (v5.3 compliant)\n\n- [ ] StructuredReasoning,\
  \ CalculatedFields\n\n- [ ] FieldValidationError, PreviewRequest, PreviewResponse\
  \ (NEW per Codex)\n\n- [ ] Enhanced WorklistResponse, SuggestBatchResponse\n\n**Phase\
  \ 3a: Enhance Worklist Endpoint**\n\n- [ ] Update `POST /api/mcp/impact/expected/worklist`\
  \ in `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py` (line \\\
  ~210)\n\n- [ ] Load hypothesis_rules and display_rules from impact_model_config.yml\n\
  \n- [ ] Add `required_output_contract` to response\n\n- [ ] Add `scoring_context`\
  \ to response\n\n**Phase 4: Fix Suggest Batch Endpoint (Codex Findings #2, #3, #4)**\n\
  \n- [ ] Fix schema mismatch: Move condition_contributes and track_contributes to\
  \ TOP-LEVEL (not inside expected_impact)\n\n- [ ] Update all field references to\
  \ match v5.3 schema structure\n\n- [ ] Remove invalid `contributes` parameter from\
  \ score calculation call (line 381-386, 452-457)\n\n- [ ] Extract all new LLM fields:\
  \ validates, primary_hypothesis_id, condition_contributes, track_contributes, assumptions,\
  \ evidence_refs, linking_reason\n\n- [ ] Build `StructuredReasoning` from LLM response\n\
  \n- [ ] Build `CalculatedFields` from score_result dict\n\n- [ ] Build `ApplyPatch`\
  \ with v5.3-compliant structure\n\n- [ ] Add `schema_version: \"v2\"` and `impact_model_version`\
  \ to response\n\n- [ ] Keep `suggested_fields` for backward compatibility (mark\
  \ deprecated)\n\n**Phase 5: Enhance Preview Endpoint (Codex Finding #5)**\n\n- [\
  \ ] Add complete `PreviewRequest` schema with parent_chain, existing_contributes,\
  \ validation flags\n\n- [ ] Implement weight sum validation (condition_contributes\
  \ + track_contributes)\n\n- [ ] Implement strategic tier hypothesis validation\n\
  \n- [ ] Implement parent chain alignment check (NEW)\n\n- [ ] Implement hypothesis\
  \ existence check (NEW)\n\n- [ ] Return complete `PreviewResponse` with structured\
  \ warnings/errors, diff, and preview\n\n**Phase 6: Enhance Apply Batch Validation\
  \ (Codex Finding #5)**\n\n- [ ] Add `FieldValidationError` model for field-level\
  \ errors\n\n- [ ] Update `ApplyBatchResponse` with field-level validation_errors\n\
  \n- [ ] Implement required field validation (expected_impact.statement)\n\n- [ ]\
  \ Implement type validation (weights must be float 0.0-1.0)\n\n- [ ] Implement constraint\
  \ validation (weight sum &lt;= 1.0)\n\n- [ ] Implement reference validation (hypothesis\
  \ IDs must exist)\n\n- [ ] Collect all errors before returning (don't fail fast)\n\
  \n**Testing**\n\n- [ ] Unit test: Verify `calculate_expected_score_with_breakdown()`\
  \ returns dict with all 8 keys\n\n- [ ] Unit test: Verify legacy `calculate_expected_score()`\
  \ returns float (backward compatibility)\n\n- [ ] Unit test: Verify v5.3 schema\
  \ compliance (condition_contributes at top level, not in expected_impact)\n\n- [\
  \ ] Integration test: Call worklist and verify `required_output_contract` + `scoring_context`\
  \ present\n\n- [ ] Integration test: Call suggest_batch and verify `apply_patch`\
  \ v5.3 schema structure\n\n- [ ] Integration test: Call preview with invalid weights\
  \ and verify structured warnings\n\n- [ ] Integration test: Call apply with field\
  \ errors and verify `FieldValidationError` structure\n\n- [ ] Integration test:\
  \ End-to-end worklist → suggest → preview → apply flow\n\n- [ ] Verify build passes\n\
  \n- [ ] Test with ChatGPT MCP to confirm improved suggestions with new fields\n\n\
  ## 참고\n\n**Reference Files:**\n\n- Plan: `/Users/gim-eunhyang/.claude/plans/fancy-toasting-storm.md`\
  \ (high-level reference only)\n- Project: `/Users/gim-eunhyang/dev/loop/public/50_Projects/Vault_System/Rounds/prj-vault-gpt/project.md`\n\
  - Impact Config SSOT: `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`\n\
  - Schema Constants: `/Users/gim-eunhyang/dev/loop/public/00_Meta/schema_constants.yaml`\n\
  \n**Estimated Time:** 8.5 hours (increased from 5.5h due to Codex findings)\n\n\
  - Phase 0: Cross-module analysis: 30 min (NEW - Codex Finding #1)\n- Phase 1: Fix\
  \ critical bug with backward compatibility: 45 min (increased from 30 min) ✅ DONE\n\
  - Phase 2: Extend config files + update LLM prompt: 90 min (NEW - Codex Findings\
  \ #3, #4) ✅ DONE\n- Phase 3: Add 10 Pydantic models (was 7): 60 min (increased from\
  \ 45 min - Codex Finding #5) ✅ DONE\n- Phase 3a: Enhance worklist: 30 min ✅ DONE\
  \ (Phase 4 in implementation)\n- Phase 4: Fix suggest_batch (schema mismatch + new\
  \ fields): 120 min (increased from 90 min - Codex Findings #2, #3, #4) ✅ DONE (Phase\
  \ 5 in implementation)\n- Phase 5: Enhance preview (complete request/response):\
  \ 45 min (increased from 30 min - Codex Finding #5) ✅ DONE (Phase 6 in implementation)\n\
  - Phase 6: Enhance apply_batch (field-level errors): 45 min (increased from 30 min\
  \ - Codex Finding #5) ✅ DONE (Phase 7 in implementation)\n- Testing: 90 min (increased\
  \ from 60 min - more test cases for v5.3 compliance) \U0001F504 NEXT\n\n## Progress\
  \ Log\n\n### 2026-01-13 - Implementation Complete\n\n**Context**: Worktree `/Users/gim-eunhyang/dev/loop-wip-1768282715`\n\
  \n**Completed**:\n\n1. ✅ Phase 1 (completed earlier): Fixed `calculate_expected_score`\
  \ bug with backward compatibility\n\n   - Added `calculate_expected_score_with_breakdown()`\
  \ function\n   - Kept legacy wrapper for projects.py, autofill.py, ai.py\n   - File:\
  \ `api/utils/impact_calculator.py`\n\n2. ✅ Phase 1 (completed earlier): Extended\
  \ config with hypothesis_rules and display_rules\n\n   - File: `impact_model_config.yml`\n\
  \n3. ✅ Phase 2: Updated LLM prompt template with v5.3 schema fields\n\n   - Added\
  \ validates, primary_hypothesis_id, condition_contributes, track_contributes\n \
  \  - Added assumptions, evidence_refs, linking_reason\n   - File: `api/prompts/expected_impact.py`\
  \ (lines 250-289)\n\n4. ✅ Phase 3: Added 10 new Pydantic models\n\n   - OutputContract,\
  \ ScoringContext, ContributeItem, ApplyPatch\n   - StructuredReasoning, CalculatedFields,\
  \ FieldValidationError\n   - EnhancedPreviewRequest, EnhancedPreviewResponse\n \
  \  - Enhanced WorklistResponse, SuggestBatchResponse, ApplyBatchResult\n   - File:\
  \ `api/models/impact_batch.py`\n\n5. ✅ Phase 4: Enhanced worklist endpoint\n\n \
  \  - Added required_output_contract with must_set, contributes_rules, hypothesis_rules\n\
  \   - Added scoring_context with impact_model_version, tier_points, display_rules\n\
  \   - File: `api/routers/impact_batch.py` (worklist endpoint, lines 269-297)\n\n\
  6. ✅ Phase 5: Fixed suggest-batch endpoint\n\n   - CRITICAL FIX: Removed invalid\
  \ `contributes` parameter from score calculation\n   - Used `calculate_expected_score_with_breakdown()`\
  \ instead of legacy function\n   - Built v5.3-compliant ApplyPatch (condition_contributes/track_contributes\
  \ at top level)\n   - Built StructuredReasoning with all LLM reasoning fields\n\
  \   - Built CalculatedFields with complete score breakdown + star rating\n   - Added\
  \ schema_version=\"v2\" and impact_model_version to response\n   - Kept suggested_fields\
  \ for backward compatibility (marked deprecated)\n   - File: `api/routers/impact_batch.py`\
  \ (suggest-batch endpoint, lines 371-522)\n\n7. ✅ Phase 6: Enhanced preview endpoint\n\
  \n   - Added weight sum validation for condition_contributes and track_contributes\n\
  \   - Added strategic tier hypothesis validation\n   - Added parent chain alignment\
  \ check\n   - Added hypothesis existence check\n   - Extended diff to include v5.3\
  \ fields\n   - File: `api/routers/impact_batch.py` (preview endpoint, lines 525-660)\n\
  \n8. ✅ Phase 7: Enhanced apply-batch with field-level validation\n\n   - Added `validate_patch_fields()`\
  \ helper function\n   - Validates required fields (expected_impact.statement)\n\
  \   - Validates weight types and ranges (0.0-1.0)\n   - Validates weight sum constraints\
  \ (&lt;= 1.0)\n   - Validates hypothesis ID references\n   - Returns structured\
  \ FieldValidationError list\n   - Updated ApplyBatchResult status to include \"\
  validation_error\"\n   - File: `api/routers/impact_batch.py` (lines 71-209 helper,\
  \ 839-962 endpoint)\n\n**Key Changes Summary**:\n\n- All endpoints now use v5.3\
  \ schema structure (condition_contributes/track_contributes at top level)\n- Score\
  \ calculation fixed: no more invalid `contributes` parameter\n- Complete breakdown\
  \ with tier_points, normalized_10, display_star_5, formula\n- Structured reasoning\
  \ with assumptions, evidence_refs, linking_reason\n- Field-level validation with\
  \ FieldValidationError model\n- Backward compatibility maintained (suggested_fields\
  \ still populated)\n\n**Files Modified**:\n\n- `api/prompts/expected_impact.py`\
  \ - Updated prompt template\n- `api/models/impact_batch.py` - Added 10 new models\n\
  - `api/routers/impact_batch.py` - Enhanced all 4 endpoints\n- `api/utils/impact_calculator.py`\
  \ - Already done (Phase 1)\n- `impact_model_config.yml` - Already done (Phase 1)\n\
  \n**Next Steps**:\n\n- Run integration tests\n- Test with ChatGPT MCP client\n-\
  \ Run Codex code review for final validation"
---
# Impact Batch API v2 - Response Schema Enhancement

## 설명

Enhance Impact Batch API response schemas to provide complete scoring context, structured reasoning, and apply-ready patches for LLM (ChatGPT MCP) suggestions.

## Notes

### Tech Spec

**Codex Review Findings Applied (2026-01-13):**

This PRD has been enhanced based on 5 critical findings from Codex code review:

1. **Finding #1: Cross-Module Impact** (projects.py, autofill.py, ai.py)
   - `calculate_expected_score()` return type change affects 4 modules, not just impact_batch.py
   - **Solution**: Create new `_with_breakdown()` function + legacy wrapper for backward compatibility
   - **Location**: Phase 0 + Phase 1

2. **Finding #2: Schema Mismatch** (v5.3 compliance)
   - Current code puts `contributes` inside `expected_impact`, but v5.3 schema uses top-level fields
   - Correct structure: `condition_contributes` and `track_contributes` at entity root, not nested
   - **Solution**: Fix all field references in suggest_batch endpoint
   - **Location**: Phase 4 Critical Fix #1

3. **Finding #3: LLM Prompt Missing Fields**
   - Prompt in `prompts/expected_impact.py` only requests 4 fields (tier, magnitude, confidence, summary)
   - v5.3 schema needs 7 additional fields: validates, primary_hypothesis_id, condition_contributes, track_contributes, assumptions, evidence_refs, linking_reason
   - **Solution**: Extend prompt template with complete v5.3 output schema
   - **Location**: Phase 2 (File 2)

4. **Finding #4: Missing Config Keys**
   - Response models reference `hypothesis_rules` and `display_rules` that don't exist in impact_model_config.yml
   - **Solution**: Extend config file with 2 new sections (hypothesis_rules, display_rules)
   - **Location**: Phase 2 (File 1)

5. **Finding #5: Incomplete Request/Response Schemas**
   - Preview/Apply endpoints missing complete validation error structure
   - No field-level validation error format in ApplyBatchResponse
   - PreviewRequest missing fields needed for validation checks
   - **Solution**: Add 3 new Pydantic models (FieldValidationError, PreviewRequest, PreviewResponse) with complete schemas
   - **Location**: Phase 3, Phase 5, Phase 6

**Impact**: Scope increased from 7 models → 10 models, 5.5 hours → 8.5 hours

---

**Architecture Compliance:**
- Parent Project: prj-vault-gpt
- Architecture Pattern: FastAPI + REST + MCP (Model Context Protocol)
- Deployment: Docker on NAS (port 8082 → 8081)
- Client: ChatGPT Developer Mode via MCP

**Critical Bug to Fix:**
Line 381-386, 452-457 in `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`:
- Passing invalid `contributes` parameter to `calculate_expected_score()`
- Function returns `float`, code expects `dict` with `["score"]` key
- This is a **BLOCKER** - must fix first

**File Structure:**
```
/Users/gim-eunhyang/dev/loop/public/api/
├── models/impact_batch.py              [MODIFY] Add 7 new Pydantic models
├── routers/impact_batch.py             [MODIFY] Fix bug + enhance 4 endpoints
├── utils/impact_calculator.py          [MODIFY] Change return type to dict
└── prompts/expected_impact.py          [READ] Verify LLM fields

/Users/gim-eunhyang/dev/loop/public/
├── impact_model_config.yml             [READ] Scoring rules SSOT
└── 00_Meta/schema_constants.yaml       [READ] Validation rules
```

**Implementation Details:**

**Phase 0: Cross-Module Impact Analysis (Codex Finding #1)**
- **CRITICAL**: `calculate_expected_score()` return type change affects 4 modules:
  1. `impact_batch.py` (lines 381-386, 452-457) - Already identified in original bug
  2. `projects.py` (lines 190-194) - Project-level scoring
  3. `autofill.py` (lines 268-307) - Autofill impact suggestions
  4. `ai.py` (lines 837-883) - AI-driven impact analysis
- **Strategy**: Create new helper function to maintain backward compatibility:
  ```python
  # In impact_calculator.py
  def calculate_expected_score_with_breakdown(tier, magnitude, confidence) -> Dict[str, Any]:
      """New function with full breakdown (Phase 1 implementation)"""
      return {
          "score": float,
          "tier_points": float,
          "confidence": float,
          "tier": str,
          "magnitude": str,
          "formula": str,
          "max_score_by_tier": float,
          "normalized_10": float,
      }

  def calculate_expected_score(tier, magnitude, confidence) -> float:
      """Legacy function - delegates to new function for compatibility"""
      return calculate_expected_score_with_breakdown(tier, magnitude, confidence)["score"]
  ```
- **Migration Plan**:
  1. Add new `_with_breakdown()` function
  2. Keep old function as compatibility wrapper
  3. Update only `impact_batch.py` to use new function
  4. Other modules (projects.py, autofill.py, ai.py) continue using legacy function
  5. Mark legacy function for deprecation in v3

**Phase 1: Fix Critical Bug (BLOCKER)**
- File: `/Users/gim-eunhyang/dev/loop/public/api/utils/impact_calculator.py`
- Function: Add `calculate_expected_score_with_breakdown()` (new function)
- Update `calculate_expected_score()` to delegate to new function
- Lines to modify: 34-69 (expand to ~80 lines for new function + wrapper)
- Impact: Only `impact_batch.py` calls new function with breakdown, other callers unaffected

**Phase 2: Extend Config Files (Codex Finding #4 - Missing Config Keys)**

**File 1:** `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`
- Add new sections for `hypothesis_rules` and `display_rules`:
  ```yaml
  # Existing sections (magnitude_points, confidence_multipliers, tier_ordering)
  # ...

  # NEW: Hypothesis linking rules (Codex Finding #4)
  hypothesis_rules:
    strategic_must_validate: true  # Strategic tier must have validates list
    max_hypotheses_per_project: 3  # Limit hypothesis links
    weight_sum_max: 1.0            # Max total weight for contributes

  # NEW: Display formatting rules (Codex Finding #4)
  display_rules:
    score_display_mode: "stars_5"   # "stars_5" | "normalized_10" | "raw"
    decimal_places: 2               # Rounding precision
    show_breakdown: true            # Include calculation breakdown in responses
    star_thresholds:                # Score → star mapping
      5: [9.0, 10.0]
      4: [7.0, 9.0]
      3: [5.0, 7.0]
      2: [3.0, 5.0]
      1: [0.0, 3.0]
  ```

**File 2:** `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py`
- Update LLM prompt template (lines 219-290) to include v5.3 schema fields:
  ```python
  # Expand existing prompt with new output schema
  EXPECTED_IMPACT_PROMPT = """
  ... (existing context) ...

  Required Output JSON Schema (v5.3 - Updated):
  {{
    // EXISTING FIELDS
    "tier": "strategic|operational|tactical",
    "impact_magnitude": "transformative|high|moderate|low|minimal",
    "confidence": 0.0-1.0,
    "summary": "Brief impact summary",

    // NEW: Hypothesis linking (Codex Finding #3)
    "validates": ["hyp-001", "hyp-002"],      // Hypothesis IDs this validates
    "primary_hypothesis_id": "hyp-001",        // Primary hypothesis (optional)

    // NEW: Strategic contribution (Codex Finding #2)
    "condition_contributes": [
      {{"condition_id": "cnd-3y-001", "weight": 0.5}},
      {{"condition_id": "cnd-3y-002", "weight": 0.3}}
    ],
    "track_contributes": [
      {{"track_id": "trk-001", "weight": 0.4}}
    ],

    // NEW: Reasoning & evidence (Codex Finding #3)
    "assumptions": ["Key assumption 1", "Key assumption 2"],
    "evidence_refs": ["Link to data", "Previous project results"],
    "linking_reason": "Why this links to selected hypotheses/conditions/tracks",

    // EXISTING: Reasoning fields
    "tier_reason": "Why this tier",
    "magnitude_reason": "Why this magnitude",
    "confidence_reason": "Confidence factors"
  }}

  IMPORTANT RULES (v5.3 Schema):
  - `expected_impact` object only contains: statement, metric, target (NO contributes inside)
  - `condition_contributes` and `track_contributes` are TOP-LEVEL fields
  - Strategic tier SHOULD have at least 1 item in `validates` list
  - Total weight in contributes lists should not exceed 1.0
  """
  ```

**Phase 3: Add New Pydantic Models**
- File: `/Users/gim-eunhyang/dev/loop/public/api/models/impact_batch.py`
- Add 10 new models (3 more than originally planned - Codex Finding #5):
  1. `OutputContract` - Required fields specification
  2. `ScoringContext` - Impact model context for LLM
  3. `ApplyPatch` - SSOT-ready patch format (v5.3 schema compliant)
  4. `StructuredReasoning` - Audit-ready reasoning breakdown
  5. `CalculatedFields` - Complete score calculation results
  6. `FieldValidationError` - Field-level error structure (NEW - Codex Finding #5)
  7. `PreviewRequest` - Complete preview request schema (NEW - Codex Finding #5)
  8. `PreviewResponse` - Complete preview response schema (NEW - Codex Finding #5)
  9. Enhanced `WorklistResponse` - Add contract + context
  10. Enhanced `SuggestBatchResponse` - Add schema_version + impact_model_version

**Phase 3a: Enhance Worklist Endpoint**
- File: `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`
- Endpoint: `POST /api/mcp/impact/expected/worklist` (~line 210)
- Add to response:
  - `required_output_contract`: must_set fields, contributes_rules, hypothesis_rules
  - `scoring_context`: impact_model_version, tier_points table, display_rules
- Load from: `impact_model_config.yml` + `00_Meta/schema_constants.yaml`

**Phase 4: Fix Suggest Batch Endpoint (Codex Findings #2, #3, #4)**

**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`
**Endpoint:** `POST /api/mcp/impact/expected/suggest-batch` (~line 280-420)

**Critical Fix #1: Schema Mismatch (Codex Finding #2)**
- **Problem**: Current code uses `contributes` as top-level field, but v5.3 schema uses:
  - `condition_contributes: List[{condition_id, weight}]` - top-level
  - `track_contributes: List[{track_id, weight}]` - top-level
  - `expected_impact: {statement, metric, target}` - nested, no contributes
- **Fix**: Update all field references:
  ```python
  # OLD (incorrect)
  apply_patch = {
      "expected_impact": {
          "statement": llm_response["statement"],
          "contributes": llm_response.get("contributes", [])  # WRONG LOCATION
      }
  }

  # NEW (correct per v5.3 schema)
  apply_patch = {
      "expected_impact": {
          "statement": llm_response["statement"],
          "metric": llm_response.get("metric"),
          "target": llm_response.get("target")
      },
      "condition_contributes": llm_response.get("condition_contributes", []),
      "track_contributes": llm_response.get("track_contributes", [])
  }
  ```

**Critical Fix #2: LLM Prompt Missing New Fields (Codex Finding #3)**
- **Problem**: Current prompt in `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py` (lines 219-266) only requests:
  - tier, impact_magnitude, confidence, summary
- **Missing fields needed by v5.3 schema**:
  - `validates: List[str]` - Hypothesis IDs this project validates
  - `primary_hypothesis_id: str` - Primary hypothesis being tested
  - `condition_contributes: List[{condition_id, weight}]` - Condition contributions
  - `track_contributes: List[{track_id, weight}]` - Track contributions
  - `assumptions: List[str]` - Key assumptions
  - `evidence_refs: List[str]` - Supporting evidence references
  - `linking_reason: str` - Why this project links to hypotheses/conditions/tracks
- **Fix Required**: Update prompt template to include new output schema:
  ```python
  # Add to prompts/expected_impact.py lines 260-280
  """
  Required Output JSON Schema (v5.3):
  {{
    "tier": "strategic|operational|tactical",
    "impact_magnitude": "transformative|high|moderate|low|minimal",
    "confidence": 0.0-1.0,
    "summary": "...",

    // NEW FIELDS (v5.3)
    "validates": ["hyp-001", "hyp-002"],           // Hypothesis IDs being tested
    "primary_hypothesis_id": "hyp-001",            // Primary hypothesis
    "condition_contributes": [
      {{"condition_id": "cnd-3y-001", "weight": 0.5}},
      {{"condition_id": "cnd-3y-002", "weight": 0.3}}
    ],
    "track_contributes": [
      {{"track_id": "trk-001", "weight": 0.4}}
    ],
    "assumptions": ["List key assumptions here"],
    "evidence_refs": ["Link to evidence/data sources"],
    "linking_reason": "Explain why this project contributes to these hypotheses/conditions/tracks",

    // REASONING FIELDS
    "tier_reason": "Why this tier was chosen",
    "magnitude_reason": "Why this magnitude",
    "confidence_reason": "Factors affecting confidence"
  }}
  """
  ```

**Critical Fix #3: Missing Config Keys (Codex Finding #4)**
- **Problem**: Response models reference keys not in `impact_model_config.yml`:
  - `hypothesis_rules` - not defined
  - `display_rules` - not defined anywhere
- **Fix Options**:
  1. **Option A (Recommended)**: Extend `impact_model_config.yml` with new sections:
     ```yaml
     # Add to impact_model_config.yml
     hypothesis_rules:
       strategic_must_validate: true
       max_hypotheses_per_project: 3
       weight_sum_max: 1.0

     display_rules:
       score_display_mode: "stars_5"  # or "normalized_10"
       decimal_places: 2
       show_breakdown: true
     ```
  2. **Option B**: Hard-code defaults in Python and document in schema_constants.yaml
  3. **Option C**: Remove from response schema (breaks client contract)
- **Decision**: Use Option A - extend config file
- **Files to modify**:
  - `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml` (add 2 new sections)
  - `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py` (load new sections)

**Critical Fix #4: Bug in Score Calculation Call**
- Remove `contributes` parameter from `calculate_expected_score_with_breakdown()` call (line 381-386, 452-457)
- Use `score_result["score"]` instead of treating result as float
- Extract all LLM fields including new v5.3 fields listed above

**Implementation Steps:**
1. Update LLM prompt template in `prompts/expected_impact.py` (lines 260-290)
2. Extend `impact_model_config.yml` with `hypothesis_rules` + `display_rules`
3. Fix score calculation call (remove contributes param)
4. Build `StructuredReasoning` from LLM response (tier_reason, magnitude_reason, assumptions, evidence_refs, linking_reason)
5. Build `CalculatedFields` from score_result dict
6. Build `ApplyPatch` with correct v5.3 schema structure (expected_impact, condition_contributes, track_contributes at correct levels)
7. Add `schema_version: "v2"` and `impact_model_version` to response
8. Keep `suggested_fields` for backward compatibility (mark deprecated)

**Phase 5: Enhance Preview Endpoint (Codex Finding #5 - Complete Request/Response)**

**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`
**Endpoint:** `POST /api/mcp/impact/expected/preview` (~line 422-500)

**Complete Request Schema (Codex Finding #5):**
```python
class PreviewRequest(BaseModel):
    """Complete request schema for preview validation"""
    project_id: str
    apply_patch: ApplyPatch  # From Phase 2 models

    # NEW: Fields needed for validation checks
    parent_chain: Optional[List[str]] = None  # For hierarchy validation
    existing_contributes: Optional[Dict] = None  # Current state for diff
    validate_weights: bool = True  # Enable weight sum check
    validate_hypothesis_links: bool = True  # Enable strategic tier check
```

**Enhanced Validation Warnings:**
1. **Weight Sum Validation**:
   - Check `condition_contributes` weight sum <= 1.0
   - Check `track_contributes` weight sum <= 1.0
   - Warning format: `{"field": "condition_contributes", "issue": "weight_sum_exceeded", "current": 1.2, "max": 1.0}`

2. **Strategic Tier Hypothesis Validation**:
   - If tier == "strategic", must have `validates` list with at least 1 hypothesis
   - Warning format: `{"field": "validates", "issue": "strategic_requires_hypothesis", "tier": "strategic"}`

3. **Parent Chain Alignment** (NEW):
   - Check if `condition_contributes` conditions are in parent project's conditions
   - Check if `track_contributes` tracks align with parent project's tracks
   - Warning format: `{"field": "condition_contributes", "issue": "condition_not_in_parent_chain", "condition_id": "cnd-3y-001"}`

4. **Hypothesis Existence Check** (NEW):
   - Verify all `validates` hypothesis IDs exist in vault
   - Warning format: `{"field": "validates", "issue": "hypothesis_not_found", "hypothesis_id": "hyp-999"}`

**Complete Response Schema (Codex Finding #5):**
```python
class PreviewResponse(BaseModel):
    """Complete response with validation results"""
    project_id: str
    status: str  # "valid" | "warnings" | "errors"

    # Validation results
    validation_passed: bool
    warnings: List[Dict[str, Any]]  # Structured warnings (non-blocking)
    errors: List[Dict[str, Any]]    # Structured errors (blocking)

    # Preview of changes
    apply_patch_preview: ApplyPatch
    impact_preview: CalculatedFields  # Show expected score

    # Diff from current state
    changes_summary: Dict[str, Any]  # {"added": [...], "removed": [...], "modified": [...]}
```

**Phase 6: Enhance Apply Batch Validation (Codex Finding #5 - Field-Level Errors)**

**File:** `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py`
**Endpoint:** `POST /api/mcp/impact/expected/apply-batch`

**Complete Request Schema:**
```python
class ApplyBatchRequest(BaseModel):
    """Batch apply with per-project patches"""
    run_id: str
    applies: List[Dict[str, Any]]  # [{project_id, apply_patch}, ...]
    dry_run: bool = False  # Preview mode without writing
```

**Enhanced Response Schema (Codex Finding #5):**
```python
class ApplyBatchResponse(BaseModel):
    """Complete response with field-level validation"""
    run_id: str
    total_requested: int
    succeeded: int
    failed: int
    dry_run: bool

    # Per-project results
    results: List[ApplyResult]

    # Summary
    summary: Dict[str, Any]

class ApplyResult(BaseModel):
    """Per-project apply result with field-level errors"""
    project_id: str
    status: str  # "success" | "validation_error" | "write_error" | "skipped"

    # Success details
    applied_patch: Optional[ApplyPatch] = None
    file_path: Optional[str] = None

    # Field-level validation errors (NEW - Codex Finding #5)
    validation_errors: List[FieldValidationError] = []

    # General error
    error: Optional[str] = None

class FieldValidationError(BaseModel):
    """Structured field-level error (NEW)"""
    field_path: str  # e.g., "expected_impact.statement", "condition_contributes[0].weight"
    error_type: str  # "missing_required" | "invalid_type" | "invalid_value" | "constraint_violation"
    message: str
    expected: Optional[Any] = None  # Expected value/type
    actual: Optional[Any] = None    # Actual value received
    constraint: Optional[str] = None  # Constraint rule violated
```

**Field-Level Validation Rules:**
1. **Required Fields**:
   - `expected_impact.statement` - must be non-empty string
   - Error: `{"field_path": "expected_impact.statement", "error_type": "missing_required", "message": "Impact statement is required"}`

2. **Type Validation**:
   - `condition_contributes[*].weight` - must be float 0.0-1.0
   - Error: `{"field_path": "condition_contributes[0].weight", "error_type": "invalid_type", "expected": "float", "actual": "string"}`

3. **Constraint Validation**:
   - Weight sum <= 1.0
   - Error: `{"field_path": "condition_contributes", "error_type": "constraint_violation", "constraint": "weight_sum_max_1.0", "actual": 1.3}`

4. **Reference Validation**:
   - Hypothesis IDs must exist
   - Error: `{"field_path": "validates[0]", "error_type": "invalid_value", "message": "Hypothesis hyp-999 not found in vault"}`

**Implementation:**
- Parse each field in `apply_patch`
- Collect all errors before returning (don't fail fast)
- Group errors by project_id
- Return structured errors for LLM to auto-fix

**API Endpoints Modified:**
- `POST /api/mcp/impact/expected/worklist` - Add contract + context
- `POST /api/mcp/impact/expected/suggest-batch` - Fix bug + add apply_patch
- `POST /api/mcp/impact/expected/preview` - Enhanced warnings
- `POST /api/mcp/impact/expected/apply-batch` - Field-level validation

**Data Models:**
```python
# New models
OutputContract(must_set: List[str], contributes_rules: Dict, hypothesis_rules: Dict)
ScoringContext(impact_model_version: str, tier_points: Dict, display_rules: Dict)
ApplyPatch(expected_impact: Dict, hypothesis_links: Dict, contributes: Dict)
StructuredReasoning(tier_reason: str, magnitude_reason: str, confidence_reason: str, assumptions: List, evidence_refs: List, linking_reason: Dict, rollup_reason: Dict)
CalculatedFields(magnitude_points: float, expected_score_raw: float, max_score_by_tier: float, normalized_score_10: float, display_star_5: float, calculation: str)

# Enhanced responses
WorklistResponse(run_id, total_matched, items, required_output_contract, scoring_context)
SuggestBatchResponse(run_id, mode, schema_version, impact_model_version, suggestions, summary)
SuggestBatchSuggestion(project_id, status, apply_patch, suggested_fields, calculated_fields, reasoning, warnings, error)
```

**Dependencies:**
- No new packages required
- Uses existing: FastAPI, Pydantic, PyYAML

**Key Functions:**
```python
# Modified function signature
def calculate_expected_score(
    tier: str,
    magnitude: str,
    confidence: float
) -> Dict[str, Any]:
    # Returns dict with score breakdown instead of float

# New helper (if needed)
def build_structured_reasoning(
    llm_response: Dict[str, Any]
) -> StructuredReasoning:
    # Parse LLM response into structured format
```

**Edge Cases:**
1. **LLM returns incomplete fields**: Use empty lists/None for optional fields (validates, contributes)
2. **Score calculation with invalid tier/magnitude**: Function should raise ValueError, catch in endpoint and return error status
3. **Weight sum > 1.0**: Add warning in preview, but don't block apply (human can override)
4. **Missing impact_model_config.yml**: Endpoint should return 500 with clear error message
5. **Backward compatibility**: Keep `suggested_fields` in response for old clients, but mark as deprecated in docs

### Todo

**Phase 0: Cross-Module Impact Analysis (Codex Finding #1)**
- [ ] Identify all callers of `calculate_expected_score()` across 4 modules: impact_batch.py, projects.py, autofill.py, ai.py
- [ ] Document migration strategy: new function with breakdown + legacy wrapper for compatibility

**Phase 1: Fix Critical Bug (BLOCKER)**
- [ ] Add `calculate_expected_score_with_breakdown()` in `/Users/gim-eunhyang/dev/loop/public/api/utils/impact_calculator.py`
- [ ] Update `calculate_expected_score()` to delegate to new function (maintain backward compatibility)
- [ ] Update only `impact_batch.py` to call new `_with_breakdown()` function (lines 381-386, 452-457)
- [ ] Other modules (projects.py, autofill.py, ai.py) continue using legacy wrapper

**Phase 2: Extend Config Files (Codex Finding #4)**
- [ ] Add `hypothesis_rules` section to `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`
- [ ] Add `display_rules` section to `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`
- [ ] Update LLM prompt in `/Users/gim-eunhyang/dev/loop/public/api/prompts/expected_impact.py` (lines 219-290) with v5.3 schema
- [ ] Add new output fields: validates, primary_hypothesis_id, condition_contributes, track_contributes, assumptions, evidence_refs, linking_reason

**Phase 3: Add New Pydantic Models (Codex Finding #5)**
- [ ] Add 10 new Pydantic models to `/Users/gim-eunhyang/dev/loop/public/api/models/impact_batch.py`
- [ ] OutputContract, ScoringContext, ApplyPatch (v5.3 compliant)
- [ ] StructuredReasoning, CalculatedFields
- [ ] FieldValidationError, PreviewRequest, PreviewResponse (NEW per Codex)
- [ ] Enhanced WorklistResponse, SuggestBatchResponse

**Phase 3a: Enhance Worklist Endpoint**
- [ ] Update `POST /api/mcp/impact/expected/worklist` in `/Users/gim-eunhyang/dev/loop/public/api/routers/impact_batch.py` (line ~210)
- [ ] Load hypothesis_rules and display_rules from impact_model_config.yml
- [ ] Add `required_output_contract` to response
- [ ] Add `scoring_context` to response

**Phase 4: Fix Suggest Batch Endpoint (Codex Findings #2, #3, #4)**
- [ ] Fix schema mismatch: Move condition_contributes and track_contributes to TOP-LEVEL (not inside expected_impact)
- [ ] Update all field references to match v5.3 schema structure
- [ ] Remove invalid `contributes` parameter from score calculation call (line 381-386, 452-457)
- [ ] Extract all new LLM fields: validates, primary_hypothesis_id, condition_contributes, track_contributes, assumptions, evidence_refs, linking_reason
- [ ] Build `StructuredReasoning` from LLM response
- [ ] Build `CalculatedFields` from score_result dict
- [ ] Build `ApplyPatch` with v5.3-compliant structure
- [ ] Add `schema_version: "v2"` and `impact_model_version` to response
- [ ] Keep `suggested_fields` for backward compatibility (mark deprecated)

**Phase 5: Enhance Preview Endpoint (Codex Finding #5)**
- [ ] Add complete `PreviewRequest` schema with parent_chain, existing_contributes, validation flags
- [ ] Implement weight sum validation (condition_contributes + track_contributes)
- [ ] Implement strategic tier hypothesis validation
- [ ] Implement parent chain alignment check (NEW)
- [ ] Implement hypothesis existence check (NEW)
- [ ] Return complete `PreviewResponse` with structured warnings/errors, diff, and preview

**Phase 6: Enhance Apply Batch Validation (Codex Finding #5)**
- [ ] Add `FieldValidationError` model for field-level errors
- [ ] Update `ApplyBatchResponse` with field-level validation_errors
- [ ] Implement required field validation (expected_impact.statement)
- [ ] Implement type validation (weights must be float 0.0-1.0)
- [ ] Implement constraint validation (weight sum <= 1.0)
- [ ] Implement reference validation (hypothesis IDs must exist)
- [ ] Collect all errors before returning (don't fail fast)

**Testing**
- [ ] Unit test: Verify `calculate_expected_score_with_breakdown()` returns dict with all 8 keys
- [ ] Unit test: Verify legacy `calculate_expected_score()` returns float (backward compatibility)
- [ ] Unit test: Verify v5.3 schema compliance (condition_contributes at top level, not in expected_impact)
- [ ] Integration test: Call worklist and verify `required_output_contract` + `scoring_context` present
- [ ] Integration test: Call suggest_batch and verify `apply_patch` v5.3 schema structure
- [ ] Integration test: Call preview with invalid weights and verify structured warnings
- [ ] Integration test: Call apply with field errors and verify `FieldValidationError` structure
- [ ] Integration test: End-to-end worklist → suggest → preview → apply flow
- [ ] Verify build passes
- [ ] Test with ChatGPT MCP to confirm improved suggestions with new fields

## 참고

**Reference Files:**
- Plan: `/Users/gim-eunhyang/.claude/plans/fancy-toasting-storm.md` (high-level reference only)
- Project: `/Users/gim-eunhyang/dev/loop/public/50_Projects/Vault_System/Rounds/prj-vault-gpt/project.md`
- Impact Config SSOT: `/Users/gim-eunhyang/dev/loop/public/impact_model_config.yml`
- Schema Constants: `/Users/gim-eunhyang/dev/loop/public/00_Meta/schema_constants.yaml`

**Estimated Time:** 8.5 hours (increased from 5.5h due to Codex findings)
- Phase 0: Cross-module analysis: 30 min (NEW - Codex Finding #1)
- Phase 1: Fix critical bug with backward compatibility: 45 min (increased from 30 min) ✅ DONE
- Phase 2: Extend config files + update LLM prompt: 90 min (NEW - Codex Findings #3, #4) ✅ DONE
- Phase 3: Add 10 Pydantic models (was 7): 60 min (increased from 45 min - Codex Finding #5) ✅ DONE
- Phase 3a: Enhance worklist: 30 min ✅ DONE (Phase 4 in implementation)
- Phase 4: Fix suggest_batch (schema mismatch + new fields): 120 min (increased from 90 min - Codex Findings #2, #3, #4) ✅ DONE (Phase 5 in implementation)
- Phase 5: Enhance preview (complete request/response): 45 min (increased from 30 min - Codex Finding #5) ✅ DONE (Phase 6 in implementation)
- Phase 6: Enhance apply_batch (field-level errors): 45 min (increased from 30 min - Codex Finding #5) ✅ DONE (Phase 7 in implementation)
- Testing: 90 min (increased from 60 min - more test cases for v5.3 compliance) 🔄 NEXT

## Progress Log

### 2026-01-13 - Implementation Complete

**Context**: Worktree `/Users/gim-eunhyang/dev/loop-wip-1768282715`

**Completed**:
1. ✅ Phase 1 (completed earlier): Fixed `calculate_expected_score` bug with backward compatibility
   - Added `calculate_expected_score_with_breakdown()` function
   - Kept legacy wrapper for projects.py, autofill.py, ai.py
   - File: `api/utils/impact_calculator.py`

2. ✅ Phase 1 (completed earlier): Extended config with hypothesis_rules and display_rules
   - File: `impact_model_config.yml`

3. ✅ Phase 2: Updated LLM prompt template with v5.3 schema fields
   - Added validates, primary_hypothesis_id, condition_contributes, track_contributes
   - Added assumptions, evidence_refs, linking_reason
   - File: `api/prompts/expected_impact.py` (lines 250-289)

4. ✅ Phase 3: Added 10 new Pydantic models
   - OutputContract, ScoringContext, ContributeItem, ApplyPatch
   - StructuredReasoning, CalculatedFields, FieldValidationError
   - EnhancedPreviewRequest, EnhancedPreviewResponse
   - Enhanced WorklistResponse, SuggestBatchResponse, ApplyBatchResult
   - File: `api/models/impact_batch.py`

5. ✅ Phase 4: Enhanced worklist endpoint
   - Added required_output_contract with must_set, contributes_rules, hypothesis_rules
   - Added scoring_context with impact_model_version, tier_points, display_rules
   - File: `api/routers/impact_batch.py` (worklist endpoint, lines 269-297)

6. ✅ Phase 5: Fixed suggest-batch endpoint
   - CRITICAL FIX: Removed invalid `contributes` parameter from score calculation
   - Used `calculate_expected_score_with_breakdown()` instead of legacy function
   - Built v5.3-compliant ApplyPatch (condition_contributes/track_contributes at top level)
   - Built StructuredReasoning with all LLM reasoning fields
   - Built CalculatedFields with complete score breakdown + star rating
   - Added schema_version="v2" and impact_model_version to response
   - Kept suggested_fields for backward compatibility (marked deprecated)
   - File: `api/routers/impact_batch.py` (suggest-batch endpoint, lines 371-522)

7. ✅ Phase 6: Enhanced preview endpoint
   - Added weight sum validation for condition_contributes and track_contributes
   - Added strategic tier hypothesis validation
   - Added parent chain alignment check
   - Added hypothesis existence check
   - Extended diff to include v5.3 fields
   - File: `api/routers/impact_batch.py` (preview endpoint, lines 525-660)

8. ✅ Phase 7: Enhanced apply-batch with field-level validation
   - Added `validate_patch_fields()` helper function
   - Validates required fields (expected_impact.statement)
   - Validates weight types and ranges (0.0-1.0)
   - Validates weight sum constraints (<= 1.0)
   - Validates hypothesis ID references
   - Returns structured FieldValidationError list
   - Updated ApplyBatchResult status to include "validation_error"
   - File: `api/routers/impact_batch.py` (lines 71-209 helper, 839-962 endpoint)

**Key Changes Summary**:
- All endpoints now use v5.3 schema structure (condition_contributes/track_contributes at top level)
- Score calculation fixed: no more invalid `contributes` parameter
- Complete breakdown with tier_points, normalized_10, display_star_5, formula
- Structured reasoning with assumptions, evidence_refs, linking_reason
- Field-level validation with FieldValidationError model
- Backward compatibility maintained (suggested_fields still populated)

**Files Modified**:
- `api/prompts/expected_impact.py` - Updated prompt template
- `api/models/impact_batch.py` - Added 10 new models
- `api/routers/impact_batch.py` - Enhanced all 4 endpoints
- `api/utils/impact_calculator.py` - Already done (Phase 1)
- `impact_model_config.yml` - Already done (Phase 1)

**Next Steps**:
- Run integration tests
- Test with ChatGPT MCP client
- Run Codex code review for final validation
